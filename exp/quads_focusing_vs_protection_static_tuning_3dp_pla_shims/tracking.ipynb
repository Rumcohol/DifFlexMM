{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking videos: Quads design (3dp pla + blue shims) for switching between focusing and protection\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import Union\n",
    "from difflexmm.plotting import generate_animation\n",
    "from difflexmm.geometry import current_coordinates\n",
    "from difflexmm.utils import save_data, load_data, SolutionData\n",
    "from problems.quads_kinetic_energy_static_tuning import OptimizationProblem\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scripts.tracking.tracking_gray_xcorr import tracking, mark_reference_frame\n",
    "from scripts.tracking.utils import smooth_fields_SG\n",
    "import jax.numpy as jnp\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)  # enable float64 type\n",
    "\n",
    "plt.style.use([\"science\", \"grid\"])\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to load/save data\n",
    "data_folder = Path(\"../../data/quads_focusing_vs_protection_static_tuning_3dp_pla_shims\")\n",
    "# Where to save plots and animations\n",
    "out_folder = Path(\"../../out/quads_focusing_vs_protection_static_tuning_3dp_pla_shims\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Either define the problem info here or load it from an optimization file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Units are mm, N, s\n",
    "\n",
    "# Retrieve design info from optimization data\n",
    "optimization_filename = f\"opt_with_angle_30_and_length_3_constraints_quads_24x18_excited_blocks_2_amplitude_7.50_loading_rate_30.00_input_shift_0_initial_angle_25.0_target_size_(2, 2)_target_shifts_((2, 2), (2, 2))_compressive_strains_(0.01, 0.08)_weights_(0.75, -0.25)\"\n",
    "optimization = OptimizationProblem.from_dict(\n",
    "    load_data(\n",
    "        f\"{data_folder}/{optimization_filename}.pkl\",\n",
    "    )\n",
    ")\n",
    "problem = optimization.forward_problem\n",
    "# Set up the forward problem\n",
    "problem.setup()\n",
    "geometry = problem.geometry\n",
    "\n",
    "# Select the best design\n",
    "design_values = optimization.design_values[-1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: Run this cell to rename the video files in human readable format!\n",
    "\n",
    "# # Grab the video files\n",
    "# video_paths = sorted(list(Path(\"videos/\").glob(\"*.mp4\")))  # Assumes filenames are in a known order\n",
    "\n",
    "# # Define the experimental parameters used to generate the videos (in the same order as the video files)\n",
    "# shaker_modes = [\"burst\"]*len(video_paths)\n",
    "# compressions = [0.]*4 + [0.01]*4 + [0.08]*5\n",
    "# voltages = [100.,200.,300.,400.]*2 + [100.,200.,300.,400.,500.]\n",
    "# frequencies = [30.]*len(video_paths)\n",
    "\n",
    "# assert len(voltages) == len(frequencies) == len(\n",
    "#     shaker_modes) == len(compressions), \"Lengths of shaker modes, voltages, frequencies, and compressions must match the number of video files\"\n",
    "\n",
    "# # Design name for subfolder name\n",
    "# design_name = optimization_filename\n",
    "\n",
    "# # Rename the files\n",
    "# for path, voltage, frequency, shaker_mode, compression in zip(video_paths, voltages, frequencies, shaker_modes, compressions):\n",
    "#     new_path = path.parent/design_name/f\"exp_shaker_{shaker_mode}_compression_{compression:.2f}_{voltage:.0f}mV_{frequency:.0f}Hz_{path.stem}{path.suffix}\"\n",
    "#     new_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     path.replace(new_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos to process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subfolder for videos and tracking data\n",
    "design_name = optimization_filename\n",
    "\n",
    "# Experimental videos to be processed\n",
    "video_paths = sorted(list(Path(f\"{data_folder}/{design_name}/videos\").glob(\"*.mp4\")),\n",
    "                     key=lambda p: p.stem[-3:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking: 0% compression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the tracked geometry i.e the reference geometry without clamped blocks\n",
    "reference_centroids = geometry.block_centroids(\n",
    "    *design_values)[problem.moving_blocks_ids]\n",
    "reference_shapes = geometry.centroid_node_vectors(\n",
    "    *design_values)[problem.moving_blocks_ids]\n",
    "\n",
    "\n",
    "def morphological_transformation(thresh):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    transformed = cv2.morphologyEx(\n",
    "        thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    transformed = cv2.morphologyEx(\n",
    "        transformed, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    # transformed = cv2.morphologyEx(transformed, cv2.MORPH_ERODE, kernel, iterations=1)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def add_clamped_blocks_data(tracked_data: SolutionData) -> SolutionData:\n",
    "    \"\"\"Add the data for the clamped blocks to the tracked data (for easier comparison with simulations).\"\"\"\n",
    "    block_centroids = problem.geometry.block_centroids(*design_values)\n",
    "    centroid_node_vectors = problem.geometry.centroid_node_vectors(\n",
    "        *design_values)\n",
    "    fields = jnp.zeros((len(tracked_data.timepoints),\n",
    "                       2, len(block_centroids), 3))\n",
    "\n",
    "    block_centroids = block_centroids.at[problem.moving_blocks_ids].set(\n",
    "        tracked_data.block_centroids)\n",
    "    centroid_node_vectors = centroid_node_vectors.at[problem.moving_blocks_ids].set(\n",
    "        tracked_data.centroid_node_vectors\n",
    "    )\n",
    "    fields = fields.at[:, :, problem.moving_blocks_ids].set(\n",
    "        tracked_data.fields)\n",
    "\n",
    "    return SolutionData(\n",
    "        block_centroids=block_centroids,\n",
    "        centroid_node_vectors=centroid_node_vectors,\n",
    "        bond_connectivity=problem.geometry.bond_connectivity(),\n",
    "        timepoints=tracked_data.timepoints,\n",
    "        fields=fields,\n",
    "    )\n",
    "\n",
    "\n",
    "# Marker placement parameters\n",
    "marker_placement_params = dict(\n",
    "    calib_xy=(0.395, 0.395),  # mm/px\n",
    "    ROI_X=(155, 1165),\n",
    "    ROI_Y=(5, 714),\n",
    "    blur_size=1,\n",
    "    threshold=52,  # 61,\n",
    "    adaptive_thresholding=True,\n",
    "    adaptive_thresholding_block=483,\n",
    "    morphological_transformation=morphological_transformation,\n",
    "    block_area=(70, 3500),\n",
    "    reference_centroids=reference_centroids,\n",
    "    reference_shapes=reference_shapes,\n",
    "    aspect_ratio_threshold=0.05,\n",
    "    # Place markers a little bit closer to the centroid to have better features for cross-correlation.\n",
    "    markers_scaled_position=0.85,\n",
    ")\n",
    "# Cross-correlation parameters\n",
    "xcorr_params = dict(\n",
    "    marker_template_size=20,  # px\n",
    "    search_window_size=30,  # px\n",
    "    upscaling_factor=5,\n",
    ")\n",
    "\n",
    "\n",
    "def show_reference_frame(video_path: Union[str, Path], frame: int = 0):\n",
    "    mark_reference_frame(\n",
    "        video_path=str(video_path),\n",
    "        **marker_placement_params,\n",
    "        frame=frame,\n",
    "        show=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def track_video(video_path: Union[str, Path], plot_centroids: bool = False, monitor_progress: bool = False):\n",
    "    tracked_data = tracking(\n",
    "        video_path=str(video_path),\n",
    "        start_end_video=(50, 400),  # (0, 600),\n",
    "        framerate=1000,\n",
    "        **marker_placement_params,\n",
    "        **xcorr_params,\n",
    "        monitor_progress=monitor_progress,\n",
    "        show_tracked_frame=False,\n",
    "    )\n",
    "    # Add the data for the clamped blocks\n",
    "    tracked_data = add_clamped_blocks_data(tracked_data)\n",
    "    # Shift timepoints to start at 0\n",
    "    tracked_data = tracked_data._replace(\n",
    "        timepoints=tracked_data.timepoints - tracked_data.timepoints[0])\n",
    "    # Smooth the data with a Savitzky-Golay filter\n",
    "    # tracked_data = tracked_data._replace(fields=smooth_fields_SG(\n",
    "    #     tracked_data.fields, window_length=[[11, 11, 21], [11, 11, 21]], polyorder=3))\n",
    "\n",
    "    if plot_centroids:\n",
    "        # Plot centroids\n",
    "        plt.figure(figsize=(8, 8*(geometry.n2_blocks+1) /\n",
    "                   geometry.n1_blocks), constrained_layout=True)\n",
    "        plt.title(r\"Centroids - frame \\#0\")\n",
    "        plt.scatter(*reference_centroids.T, label=\"Reference\")\n",
    "        plt.scatter(\n",
    "            *tracked_data.block_centroids[problem.moving_blocks_ids].T, label=\"Tracked\")\n",
    "        plt.scatter(\n",
    "            *tracked_data.block_centroids[problem.clamped_blocks_ids].T, label=\"Clamped\")\n",
    "        for i, pt in enumerate(tracked_data.block_centroids):\n",
    "            plt.text(*pt, f\"{i}\")\n",
    "        plt.axis(\"equal\")\n",
    "        plt.legend(bbox_to_anchor=(0.5, -0.08), loc='center', ncol=3)\n",
    "\n",
    "    return tracked_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process one video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_reference_frame(video_path=video_paths[0], frame=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = track_video(video_path=video_paths[4],\n",
    "#                 plot_centroids=False, monitor_progress=True)\n",
    "\n",
    "# # Animation tracked experiments\n",
    "# xlim, ylim = problem.geometry.get_xy_limits(\n",
    "#     *design_values) + 0.5*problem.geometry.spacing * jnp.array([-1, 1])\n",
    "\n",
    "# generate_animation(\n",
    "#     t._replace(fields=smooth_fields_SG(\n",
    "#         t.fields, window_length=[[11, 11, 19], [21, 21, 25]], polyorder=2)\n",
    "#     ),\n",
    "#     frame_range=jnp.arange(0, t.timepoints.shape[0], 2),\n",
    "#     field=\"u\",\n",
    "#     deformed=True,\n",
    "#     out_filename=f\"{video_paths[4].stem}.mp4\",\n",
    "#     xlim=xlim,\n",
    "#     ylim=ylim,\n",
    "#     figsize=(8, 5),\n",
    "#     fps=30,\n",
    "#     dpi=300,\n",
    "#     cmap=\"inferno\",\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process videos in bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths[0].with_suffix(\".pkl\").name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the videos that we want to process\n",
    "all_videos = pd.DataFrame({\n",
    "    \"label\": [p.stem for p in video_paths],\n",
    "    \"shaker_mode\": [p.stem.split(\"_\")[-6] for p in video_paths],\n",
    "    \"compression\": [float(p.stem.split(\"_\")[-4]) for p in video_paths],\n",
    "    \"voltage\": [float(p.stem.split(\"_\")[-3][:-2]) for p in video_paths],\n",
    "    \"frequency\": [float(p.stem.split(\"_\")[-2][:-2]) for p in video_paths],\n",
    "    \"path\": video_paths,\n",
    "})\n",
    "videos_to_process = all_videos[\n",
    "        (all_videos[\"compression\"] == 0.)\n",
    "]\n",
    "# videos_to_process = all_videos\n",
    "\n",
    "# Track each video and save the tracked data\n",
    "for path in videos_to_process[\"path\"]:\n",
    "    tracked_data = track_video(path)\n",
    "    save_data(f\"{data_folder}/{design_name}/dynamic-data/tracking_exp/{path.stem}.pkl\", tracked_data._asdict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking: 1% compression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reference_simulation_data(compressive_strain):\n",
    "    \"\"\"Compute the reference simulation data for the tracked experiments.\"\"\"\n",
    "    return problem.solve(\n",
    "        design_values,\n",
    "        amplitude=optimization.forward_input.amplitude[0],\n",
    "        loading_rate=optimization.forward_input.loading_rate[0],\n",
    "        compressive_strain=compressive_strain,\n",
    "        compressive_strain_rate=optimization.forward_input.compressive_strain_rate[0],\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_initial_centroids_and_shapes(solution_data: SolutionData):\n",
    "    \"\"\"Compute the initial centroids and shapes of the tracked blocks.\"\"\"\n",
    "    initial_centroids = (solution_data.block_centroids +\n",
    "                         solution_data.fields[0, 0, :, :2])[problem.moving_blocks_ids]\n",
    "    initial_shapes = current_coordinates(\n",
    "        solution_data.centroid_node_vectors,\n",
    "        0*solution_data.block_centroids,\n",
    "        solution_data.fields[0, 0, :, 2],\n",
    "        0*solution_data.fields[0, 0, :, :2],\n",
    "    )[problem.moving_blocks_ids]\n",
    "    return initial_centroids, initial_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tracked geometry i.e the reference geometry without clamped blocks using the simulated response under compressive strain\n",
    "# Compression of 0.01 is saved already so no need to recompute\n",
    "reference_simulation_data = problem.solution_data[0]\n",
    "reference_centroids, reference_shapes = compute_initial_centroids_and_shapes(\n",
    "    solution_data=reference_simulation_data\n",
    ")\n",
    "\n",
    "\n",
    "def morphological_transformation(thresh):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    transformed = cv2.morphologyEx(\n",
    "        thresh, cv2.MORPH_ERODE, kernel, iterations=2)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def add_clamped_blocks_data(tracked_data: SolutionData) -> SolutionData:\n",
    "    \"\"\"Add the data for the clamped blocks to the tracked data (for easier comparison with simulations).\"\"\"\n",
    "    # Add simulated compression step to the tracked data\n",
    "    fields = jnp.zeros(\n",
    "        (tracked_data.fields.shape[0], *reference_simulation_data.fields.shape[1:]))\n",
    "    fields = fields.at[:, :, problem.moving_blocks_ids].set(\n",
    "        tracked_data.fields)\n",
    "    fields = fields.at[:, 0].add(reference_simulation_data.fields[0, 0])\n",
    "    return reference_simulation_data._replace(\n",
    "        fields=fields,\n",
    "        timepoints=tracked_data.timepoints,\n",
    "    )\n",
    "\n",
    "\n",
    "# Marker placement parameters\n",
    "marker_placement_params = dict(\n",
    "    calib_xy=(0.395, 0.395),  # mm/px\n",
    "    ROI_X=(155, 1165),\n",
    "    ROI_Y=(5, 714),  # (5, 714),\n",
    "    blur_size=1,\n",
    "    threshold=52,  # 61,\n",
    "    adaptive_thresholding=True,\n",
    "    adaptive_thresholding_block=483,\n",
    "    morphological_transformation=morphological_transformation,\n",
    "    block_area=(10, 3500),\n",
    "    reference_centroids=reference_centroids,\n",
    "    reference_shapes=reference_shapes,\n",
    "    aspect_ratio_threshold=0.05,\n",
    "    # Place markers a little bit closer to the centroid to have better features for cross-correlation.\n",
    "    markers_scaled_position=0.85,\n",
    "    # masked_areas=[((225, 230), (314, 320))],\n",
    ")\n",
    "# Cross-correlation parameters\n",
    "xcorr_params = dict(\n",
    "    marker_template_size=20,  # px\n",
    "    search_window_size=30,  # px\n",
    "    upscaling_factor=5,\n",
    ")\n",
    "\n",
    "\n",
    "def show_reference_frame(video_path: Union[str, Path], frame: int = 0):\n",
    "    markers, centroids = mark_reference_frame(\n",
    "        video_path=str(video_path),\n",
    "        **marker_placement_params,\n",
    "        frame=frame,\n",
    "        show=True,\n",
    "    )\n",
    "    print(f\"Number of marked blocks: {len(markers)}\")\n",
    "\n",
    "\n",
    "def track_video(video_path: Union[str, Path], plot_centroids: bool = False, monitor_progress: bool = False):\n",
    "    tracked_data = tracking(\n",
    "        video_path=str(video_path),\n",
    "        start_end_video=(50, 400),  # (0, 600),\n",
    "        framerate=1000,\n",
    "        **marker_placement_params,\n",
    "        **xcorr_params,\n",
    "        monitor_progress=monitor_progress,\n",
    "        show_tracked_frame=False,\n",
    "    )\n",
    "    # Add the data for the clamped blocks\n",
    "    tracked_data = add_clamped_blocks_data(tracked_data)\n",
    "    # Shift timepoints to start at 0\n",
    "    tracked_data = tracked_data._replace(\n",
    "        timepoints=tracked_data.timepoints - tracked_data.timepoints[0])\n",
    "    # Smooth the data with a Savitzky-Golay filter\n",
    "    # tracked_data = tracked_data._replace(fields=smooth_fields_SG(\n",
    "    #     tracked_data.fields, window_length=[[11, 11, 21], [11, 11, 21]], polyorder=3))\n",
    "\n",
    "    if plot_centroids:\n",
    "        # Plot centroids\n",
    "        plt.figure(figsize=(8, 8*(geometry.n2_blocks+1) /\n",
    "                   geometry.n1_blocks), constrained_layout=True)\n",
    "        plt.title(r\"Centroids - frame \\#0\")\n",
    "        plt.scatter(*reference_centroids.T, label=\"Reference\")\n",
    "        plt.scatter(\n",
    "            *tracked_data.block_centroids[problem.moving_blocks_ids].T, label=\"Tracked\")\n",
    "        plt.scatter(\n",
    "            *tracked_data.block_centroids[problem.clamped_blocks_ids].T, label=\"Clamped\")\n",
    "        for i, pt in enumerate(tracked_data.block_centroids):\n",
    "            plt.text(*pt, f\"{i}\")\n",
    "        plt.axis(\"equal\")\n",
    "        plt.legend(bbox_to_anchor=(0.5, -0.08), loc='center', ncol=3)\n",
    "\n",
    "    return tracked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process one video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_reference_frame(video_path=video_paths[4], frame=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = track_video(video_path=video_paths[8],\n",
    "#                 plot_centroids=False, monitor_progress=True)\n",
    "# # Animation tracked experiments\n",
    "# xlim, ylim = problem.geometry.get_xy_limits(\n",
    "#     *design_values) + 0.5*problem.geometry.spacing * jnp.array([-1, 1])\n",
    "\n",
    "# generate_animation(\n",
    "#     t._replace(fields=smooth_fields_SG(\n",
    "#         t.fields, window_length=[[11, 11, 19], [21, 21, 25]], polyorder=2)\n",
    "#     ),\n",
    "#     frame_range=jnp.arange(0, t.timepoints.shape[0], 2),\n",
    "#     field=\"v\",\n",
    "#     deformed=True,\n",
    "#     out_filename=f\"{video_paths[8].stem}.mp4\",\n",
    "#     xlim=xlim,\n",
    "#     ylim=ylim,\n",
    "#     figsize=(8, 5),\n",
    "#     fps=30,\n",
    "#     dpi=300,\n",
    "#     cmap=\"inferno\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process videos in bulk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the videos that we want to process\n",
    "all_videos = pd.DataFrame({\n",
    "    \"label\": [p.stem for p in video_paths],\n",
    "    \"shaker_mode\": [p.stem.split(\"_\")[-6] for p in video_paths],\n",
    "    \"compression\": [float(p.stem.split(\"_\")[-4]) for p in video_paths],\n",
    "    \"voltage\": [float(p.stem.split(\"_\")[-3][:-2]) for p in video_paths],\n",
    "    \"frequency\": [float(p.stem.split(\"_\")[-2][:-2]) for p in video_paths],\n",
    "    \"path\": video_paths,\n",
    "})\n",
    "videos_to_process = all_videos[\n",
    "        (all_videos[\"compression\"] == 0.01)\n",
    "]\n",
    "# videos_to_process = all_videos\n",
    "\n",
    "# Track each video and save the tracked data\n",
    "for path in videos_to_process[\"path\"]:\n",
    "    tracked_data = track_video(path)\n",
    "    save_data(f\"{data_folder}/{design_name}/dynamic-data/tracking_exp/{path.stem}.pkl\", tracked_data._asdict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking: 8% compression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reference_simulation_data(compressive_strain):\n",
    "    \"\"\"Compute the reference simulation data for the tracked experiments.\"\"\"\n",
    "    return problem.solve(\n",
    "        design_values,\n",
    "        amplitude=optimization.forward_input.amplitude[0],\n",
    "        loading_rate=optimization.forward_input.loading_rate[0],\n",
    "        compressive_strain=compressive_strain,\n",
    "        compressive_strain_rate=optimization.forward_input.compressive_strain_rate[0],\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_initial_centroids_and_shapes(solution_data: SolutionData):\n",
    "    \"\"\"Compute the initial centroids and shapes of the tracked blocks.\"\"\"\n",
    "    initial_centroids = (solution_data.block_centroids +\n",
    "                         solution_data.fields[0, 0, :, :2])[problem.moving_blocks_ids]\n",
    "    initial_shapes = current_coordinates(\n",
    "        solution_data.centroid_node_vectors,\n",
    "        0*solution_data.block_centroids,\n",
    "        solution_data.fields[0, 0, :, 2],\n",
    "        0*solution_data.fields[0, 0, :, :2],\n",
    "    )[problem.moving_blocks_ids]\n",
    "    return initial_centroids, initial_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tracked geometry i.e the reference geometry without clamped blocks using the simulated response under compressive strain\n",
    "# Compression of 0.08 is saved already so no need to recompute\n",
    "reference_simulation_data = problem.solution_data[-1]\n",
    "reference_centroids, reference_shapes = compute_initial_centroids_and_shapes(\n",
    "    solution_data=reference_simulation_data\n",
    ")\n",
    "\n",
    "\n",
    "def morphological_transformation(thresh):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    transformed = cv2.morphologyEx(\n",
    "        thresh, cv2.MORPH_ERODE, kernel, iterations=2)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def add_clamped_blocks_data(tracked_data: SolutionData) -> SolutionData:\n",
    "    \"\"\"Add the data for the clamped blocks to the tracked data (for easier comparison with simulations).\"\"\"\n",
    "    # Add simulated compression step to the tracked data\n",
    "    fields = jnp.zeros(\n",
    "        (tracked_data.fields.shape[0], *reference_simulation_data.fields.shape[1:]))\n",
    "    fields = fields.at[:, :, problem.moving_blocks_ids].set(\n",
    "        tracked_data.fields)\n",
    "    fields = reference_simulation_data.fields[0] + fields\n",
    "    return reference_simulation_data._replace(\n",
    "        fields=fields,\n",
    "        timepoints=tracked_data.timepoints,\n",
    "    )\n",
    "\n",
    "\n",
    "# Marker placement parameters\n",
    "marker_placement_params = dict(\n",
    "    calib_xy=(0.395, 0.395),  # mm/px\n",
    "    ROI_X=(155, 1165),\n",
    "    ROI_Y=(35, 680),  # (5, 714),\n",
    "    blur_size=1,\n",
    "    threshold=50,  # 16,  # 61,\n",
    "    adaptive_thresholding=True,\n",
    "    adaptive_thresholding_block=333,\n",
    "    morphological_transformation=morphological_transformation,\n",
    "    block_area=(10, 3500),\n",
    "    reference_centroids=reference_centroids,\n",
    "    reference_shapes=reference_shapes,\n",
    "    aspect_ratio_threshold=0.05,\n",
    "    # Place markers a little bit closer to the centroid to have better features for cross-correlation.\n",
    "    markers_scaled_position=0.8,\n",
    "    masked_areas=[\n",
    "        ((65, 70), (450, 454)),\n",
    "        ((525, 530), (268, 271)),\n",
    "        ((624, 627), (155, 157)),\n",
    "        ((876, 879), (325, 328)),\n",
    "        ((497, 500), (488, 490)),\n",
    "        ((816, 819), (304, 307)),\n",
    "    ],\n",
    ")\n",
    "# Cross-correlation parameters\n",
    "xcorr_params = dict(\n",
    "    marker_template_size=20,  # px\n",
    "    search_window_size=30,  # px\n",
    "    upscaling_factor=5,\n",
    ")\n",
    "\n",
    "\n",
    "def show_reference_frame(video_path: Union[str, Path], frame: int = 0):\n",
    "    markers, centroids = mark_reference_frame(\n",
    "        video_path=str(video_path),\n",
    "        **marker_placement_params,\n",
    "        frame=frame,\n",
    "        show=True,\n",
    "    )\n",
    "    print(f\"Number of marked blocks: {len(markers)}\")\n",
    "\n",
    "\n",
    "def track_video(video_path: Union[str, Path], plot_centroids: bool = False, monitor_progress: bool = False):\n",
    "    tracked_data = tracking(\n",
    "        video_path=str(video_path),\n",
    "        start_end_video=(50, 400),  # (0, 600),\n",
    "        framerate=1000,\n",
    "        **marker_placement_params,\n",
    "        **xcorr_params,\n",
    "        monitor_progress=monitor_progress,\n",
    "        show_tracked_frame=False,\n",
    "    )\n",
    "    # Add the data for the clamped blocks\n",
    "    tracked_data = add_clamped_blocks_data(tracked_data)\n",
    "    # Shift timepoints to start at 0\n",
    "    tracked_data = tracked_data._replace(\n",
    "        timepoints=tracked_data.timepoints - tracked_data.timepoints[0])\n",
    "    # Smooth the data with a Savitzky-Golay filter\n",
    "    # tracked_data = tracked_data._replace(fields=smooth_fields_SG(\n",
    "    #     tracked_data.fields, window_length=[[11, 11, 21], [11, 11, 21]], polyorder=3))\n",
    "\n",
    "    if plot_centroids:\n",
    "        # Plot centroids\n",
    "        plt.figure(figsize=(8, 8*(geometry.n2_blocks+1) /\n",
    "                   geometry.n1_blocks), constrained_layout=True)\n",
    "        plt.title(r\"Centroids - frame \\#0\")\n",
    "        plt.scatter(*reference_centroids.T, label=\"Reference\")\n",
    "        plt.scatter(\n",
    "            *tracked_data.block_centroids[problem.moving_blocks_ids].T, label=\"Tracked\")\n",
    "        plt.scatter(\n",
    "            *tracked_data.block_centroids[problem.clamped_blocks_ids].T, label=\"Clamped\")\n",
    "        for i, pt in enumerate(tracked_data.block_centroids):\n",
    "            plt.text(*pt, f\"{i}\")\n",
    "        plt.axis(\"equal\")\n",
    "        plt.legend(bbox_to_anchor=(0.5, -0.08), loc='center', ncol=3)\n",
    "\n",
    "    return tracked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process one video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_reference_frame(video_path=video_paths[-1], frame=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = track_video(video_path=video_paths[-3],\n",
    "#                 plot_centroids=False, monitor_progress=True)\n",
    "# # Animation tracked experiments\n",
    "# xlim, ylim = problem.geometry.get_xy_limits(\n",
    "#     *design_values) + 0.5*problem.geometry.spacing * jnp.array([-1, 1])\n",
    "\n",
    "# generate_animation(\n",
    "#     t._replace(fields=smooth_fields_SG(\n",
    "#         t.fields, window_length=[[11, 11, 19], [21, 21, 25]], polyorder=2)\n",
    "#     ),\n",
    "#     frame_range=jnp.arange(0, t.timepoints.shape[0], 2),\n",
    "#     field=\"v\",\n",
    "#     deformed=True,\n",
    "#     out_filename=f\"{video_paths[-3].stem}.mp4\",\n",
    "#     xlim=xlim,\n",
    "#     ylim=ylim,\n",
    "#     figsize=(8, 5),\n",
    "#     fps=30,\n",
    "#     dpi=300,\n",
    "#     cmap=\"inferno\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process videos in bulk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the videos that we want to process\n",
    "all_videos = pd.DataFrame({\n",
    "    \"label\": [p.stem for p in video_paths],\n",
    "    \"shaker_mode\": [p.stem.split(\"_\")[-6] for p in video_paths],\n",
    "    \"compression\": [float(p.stem.split(\"_\")[-4]) for p in video_paths],\n",
    "    \"voltage\": [float(p.stem.split(\"_\")[-3][:-2]) for p in video_paths],\n",
    "    \"frequency\": [float(p.stem.split(\"_\")[-2][:-2]) for p in video_paths],\n",
    "    \"path\": video_paths,\n",
    "})\n",
    "videos_to_process = all_videos[\n",
    "        (all_videos[\"compression\"] == 0.08)\n",
    "]\n",
    "# videos_to_process = all_videos\n",
    "\n",
    "# Track each video and save the tracked data\n",
    "for path in videos_to_process[\"path\"]:\n",
    "    tracked_data = track_video(path)\n",
    "    save_data(f\"{data_folder}/{design_name}/dynamic-data/tracking_exp/{path.stem}.pkl\", tracked_data._asdict())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tracking data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all data files in the dynamic-data folder\n",
    "tracked_data_paths = sorted(list(Path(\n",
    "    f\"{data_folder}/{design_name}/dynamic-data/tracking_exp/\").glob(\"*.pkl\")), key=lambda p: p.stem[-3:])\n",
    "\n",
    "# Load the tracked data as a dataframe\n",
    "# NOTE: Make sure the filenames are consistent as voltages and frequencies are extracted from the filenames.\n",
    "tracked_data = pd.DataFrame({\n",
    "    \"label\": [p.stem for p in tracked_data_paths],\n",
    "    \"shaker_mode\": [p.stem.split(\"_\")[-6] for p in tracked_data_paths],\n",
    "    \"compression\": [float(p.stem.split(\"_\")[-4]) for p in tracked_data_paths],\n",
    "    \"voltage\": [float(p.stem.split(\"_\")[-3][:-2]) for p in tracked_data_paths],\n",
    "    \"frequency\": [float(p.stem.split(\"_\")[-2][:-2]) for p in tracked_data_paths],\n",
    "    \"data\": [SolutionData(**load_data(p)) for p in tracked_data_paths],\n",
    "})\n",
    "\n",
    "excited_blocks_ids = problem.driven_blocks_ids\n",
    "# Smooth tracking data\n",
    "tracked_data.data = tracked_data.apply(\n",
    "    lambda row: row.data._replace(fields=smooth_fields_SG(\n",
    "        row.data.fields, window_length=[[11, 11, 19], [21, 21, 25]], polyorder=2)),\n",
    "    axis=1,\n",
    ")\n",
    "tracked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot input signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shaker_input(tracked_data, DOF=0):\n",
    "    fig, axes = plt.subplots(figsize=(7, 3), constrained_layout=True)\n",
    "\n",
    "    for row in tracked_data.itertuples():\n",
    "        axes.plot(\n",
    "            row.data.timepoints,\n",
    "            row.data.fields[:, 0, excited_blocks_ids[0], DOF],\n",
    "            label=f\"{row.label.split('_')[-1]}: {row.voltage:.0f}mV, {row.frequency:.0f}Hz\",\n",
    "            lw=2,\n",
    "        )\n",
    "\n",
    "    axes.axhline(0, color=\"black\", ls=\"-\", lw=1)\n",
    "    axes.set(xlabel=\"Time [s]\", ylabel=\"Displacement [mm]\")\n",
    "    axes.set(title=f\"Shaker input - DOF {DOF}\")\n",
    "    axes.legend(loc='upper right')\n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shaker_input(\n",
    "    tracked_data[tracked_data.compression == 0.0],\n",
    "    DOF=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shaker_input(\n",
    "    tracked_data[tracked_data.compression == 0.01],\n",
    "    DOF=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shaker_input(\n",
    "    tracked_data[tracked_data.compression == 0.08],\n",
    "    DOF=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation of tracked experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation tracked experiments\n",
    "xlim, ylim = problem.geometry.get_xy_limits(\n",
    "    *design_values) + 0.5*problem.geometry.spacing * jnp.array([-1, 1])\n",
    "\n",
    "for row in tracked_data.itertuples():\n",
    "    generate_animation(\n",
    "        row.data,\n",
    "        frame_range=jnp.arange(0, row.data.timepoints.shape[0], 2),\n",
    "        field=\"u\",\n",
    "        deformed=True,\n",
    "        out_filename=f\"{out_folder}/{optimization_filename}/tracking_exp/{row.label}\",\n",
    "        xlim=xlim,\n",
    "        ylim=ylim,\n",
    "        figsize=(8, 5),\n",
    "        fps=30,\n",
    "        dpi=300,\n",
    "        cmap=\"inferno\",\n",
    "        grid=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blockymetamaterials-fbuxbt7l-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
